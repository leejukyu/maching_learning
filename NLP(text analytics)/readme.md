## 1. 용어 정리
#### 1) 공부할 부분
- 텍스트 분류(Text Classification): 문서가 특정 카테고리에 속하는 것을 예측, 지도학습 ex) 스팸 검출, 신문 기사 분류
- 감정 분석(Sentiment Analysis): 텍스트에서 나타나는 주관적 요소를 분석, 지도, 비지도 학습
- 텍스트 요약(Summarization): 중요한 주제나 중심 사상을 추출하는 기법 ex) 토픽 모델링
- 텍스트 군집화(Clustering)와 유사도 측정: 비슷한 유형의 문서에 대해 군집화 수행, 비지도 학습
#### 2) 수행 프로세스
- (1) 텍스트 사전 준비작업(전처리): 클렌징, 대/소문자 변경, 특수문자 삭제 등의 클렌징 작업
- (2) 피처 벡터화/추출: 텍스트를 다수의 피처로 추출하고 빈도수와 같은 숫자 값을 부여하여 벡터값으로 변환하는 단계
  - BOW - Count, TF-IDF
  - Word2Vec
- (3) MS 모델 수립 및 학습/예측/평가
#### 3) 대표적인 NLP와 텍스트 분석 패키지
- NLTK(Natural Language Toolkit for Python): 파이썬의 대표적인 NLP패키지, 거의 모든 영역 커버, *수행 속도가 느려 실제 대량의 데이터에선 활용하기 힘듬*
- Gensim: *토픽* 모델링 분야에서 두각
- SpaCy: 뛰어난 수행 성능으로 최근 가장 주목
## 2. [텍스트 사전 준비작업 - 텍스트 정규화](text_preprocessing.ipynb)
#### 1) 클렌징: 불필요한 문자, 기호 등을 사전에 제거
#### 2) 텍스트 토큰화
- 문장 토큰화: 마침표, 개행문자 등 문장의 마지막을 뜻하는 기호에 따라 분리하는 것이 일반적
- 단어 토큰화: 기본적으로 공백, 콤마, 마침표, 개행문자 등으로 단어를 분리하지만, 정규 표현식을 이용해 다양한 유형으로 수행, 단어의 순서가 중요하지 않으면 문장 토큰화를 하지 않고 바로 단어 토큰화를 해도 충분
- n_gram: 단어별로 토큰화 하면 문맥적인 의미가 무시됨 -> 연속된 n개의 단어를 하나의 토큰화 단위로 분리
#### 3) 스톱 워드 제거: 분석에 큰 의미가 없는 단어 제거
#### 4) Stemming과 Lemmatization: 문법적 또는 의미적으로 변화하는 단어의 원형을 찾음
- Lemmatization: Stemming보다 정교하며 의미론적인 기반에서 단어의 원형을 찾음, 더 오래 걸림, WordNetLemmatizer
- Stemmer: Porter, Lancaster, Snowball Stemmer
## 3. BOW(Bag of Words)
- 문서가 가지는 모든 단어를 문맥이나 순서를 무시하고 일괄적으로 단어에 대해 빈도 값을 부여해 피처값을 추출하는 모델
- 장점 : 쉽고 빠른 구축, 예상보다 문서의 특징을 잘 나타낼 수 있는 모델, 전통적으로 여러 분야에서 활용도가 높음
- 단점 : 문맥의미 반영 부족, 희소 행렬 문제(행렬의 대부분이 0으로 채워진 행렬)
#### 1) [피처 백터화](Vectorizer.ipynb)
- 카운트 기반의 벡터화 : 해당 단어가 나타나는 횟수, 카운트 값이 높을수록 중요한 단어로 인식, 문장에서 자주 사용될 수 밖에 없는 단어까지 높은 값을 부여
- TF-IDF : 개별 문서에서 자주 나타나는 단어에 높은 가중치를 주되, 모든 문서에서 전반적으로 자주 나타나는 단어는 패널티를 줌
- 파라미터
  - max_df : 너무 높은 빈도수를 가지는 단어 피처를 제외
  - min_df : 너무 낮은 빈도수를 가지는 단어 피처를 제외
  - max_features : 추출하는 피처의 개수 제한
#### 2) 희소행렬
- 물리적으로 적은 메모리 공간을 차지할 수 있도록 변환 -> COO형식, CSR형식
- COO : 0이 아닌 데이터만 별도의 데이터 배열에 저장하고 그 데이터가 가리키는 행과 열의 위치를 별도의 배열로 저장
- CSR : 큰 희소 행렬을 저장하고 계산을 수행, 행 위치 배열 내에 있는 고유한 값의 시작 위치만 다시 별도의 위치 배열로 가지는 변환
## 4. 감정분석
#### 1) 지도학습 기반
- 일반적인 텍스트 기반의 분류와 거의 동일
- 이진분류
#### 2) 비지도학습 기반
- Lexicon 기반 = 감성어휘사전
- 감정사전
  - SentiWordNet : Synset별로 3가지 감성 점수(긍정, 부정, 객관성), 정확도가 그리 높진 않음
  - VADER : 소셜 미디어의 텍스트에 대한 감성 분석, 빠르고 대용량 가능, 뛰어난 결과
  - Pattern : 파이썬 2.X에서만 동작
- VANDER의 경우 : 감성 점수를 구한 뒤, 특정 임계값 이상이면 긍정, 그렇지 않으면 부정으로 판단, -1에서 1사이값, 보통 0.1 이상이면 긍정
#### 3) 군집화
- 비슷한 텍스트 구성의 문서를 군집화
- 각 군집에 속한 문서는 핵심 단어를 주축으로 군집화
#### 4) 문서 유사도
- 주로 코사인 유사도를 
- 코사인 유사도 : 두 벡터 사이의 사잇각을 구해서 얼마나 유사한지 수치로 적용
